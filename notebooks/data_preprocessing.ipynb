{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:17.944701Z",
     "start_time": "2024-04-13T12:49:14.288263Z"
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:17.949207Z",
     "start_time": "2024-04-13T12:49:17.946004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_shuffled_images(data_dir):\n",
    "    \"\"\"\n",
    "    Reads images from the specified directory, shuffles them, and returns a list of tuples,\n",
    "    where each tuple contains an image array and its corresponding label.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The directory containing the image data.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains an image array and its corresponding label.\n",
    "    \"\"\"\n",
    "    classes = os.listdir(data_dir)[1:]\n",
    "    data = []\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        class_label = 1 if class_name == 'Malignant' else 0\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, img_name)\n",
    "            image = np.array(Image.open(image_path))\n",
    "            label = class_label\n",
    "            data.append((image, label))\n",
    "    np.random.shuffle(data)\n",
    "    return data"
   ],
   "id": "c7eae0069cf6cf86",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:17.951642Z",
     "start_time": "2024-04-13T12:49:17.949969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_train_dir = \"../data/train\"  # Directory containing the training data\n",
    "data_test_dir = \"../data/test\"    # Directory containing the testing data"
   ],
   "id": "e40a148044e6a283",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:24.292286Z",
     "start_time": "2024-04-13T12:49:17.952426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = get_shuffled_images(data_train_dir)  # Retrieve shuffled image data for training from the specified directory\n",
    "test_data = get_shuffled_images(data_test_dir)    # Retrieve shuffled image data for testing from the specified directory"
   ],
   "id": "ed2292ff21b75652",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:24.295328Z",
     "start_time": "2024-04-13T12:49:24.293062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate over the labels of the first 15 images in the training data and print them\n",
    "for image, label in train_data[:15]:\n",
    "    print(f\"label: {label}\")"
   ],
   "id": "7d63f874135bf1c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0\n",
      "label: 0\n",
      "label: 1\n",
      "label: 1\n",
      "label: 1\n",
      "label: 0\n",
      "label: 0\n",
      "label: 0\n",
      "label: 0\n",
      "label: 0\n",
      "label: 0\n",
      "label: 1\n",
      "label: 1\n",
      "label: 0\n",
      "label: 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:24.297969Z",
     "start_time": "2024-04-13T12:49:24.296052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a transformation pipeline to convert images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ],
   "id": "5d8c624a85c70282",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:27.883503Z",
     "start_time": "2024-04-13T12:49:24.300156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transformed_train_data = [(transform(image), torch.tensor(label)) for image, label in train_data]  # Apply transformation to training data\n",
    "transformed_test_data = [(transform(image), torch.tensor(label)) for image, label in test_data]    # Apply transformation to testing data"
   ],
   "id": "eca9dca9acc703be",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:29.957792Z",
     "start_time": "2024-04-13T12:49:27.884261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_images = torch.stack([item[0] for item in transformed_train_data])  # Stack transformed training images into a single tensor\n",
    "train_labels = torch.stack([item[1] for item in transformed_train_data])  # Stack transformed training labels into a single tensor\n",
    "test_images_tensor = torch.stack([item[0] for item in transformed_test_data])  # Stack transformed testing images into a single tensor\n",
    "test_labels_tensor = torch.stack([item[1] for item in transformed_test_data])  # Stack transformed testing labels into a single tensor"
   ],
   "id": "37ba1e8504872bb1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:33.667793Z",
     "start_time": "2024-04-13T12:49:29.958789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_val_images_numpy = train_images.numpy()  # Convert training images tensor to NumPy array\n",
    "train_val_labels_numpy = train_labels.numpy()  # Convert training labels tensor to NumPy array\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_images_numpy, val_images_numpy, train_labels_numpy, val_labels_numpy = train_test_split(\n",
    "    train_val_images_numpy,\n",
    "    train_val_labels_numpy,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=train_val_labels_numpy  # Maintain class balance during splitting\n",
    ")"
   ],
   "id": "2d4460201789db9c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:36.954029Z",
     "start_time": "2024-04-13T12:49:33.668715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_images_tensor = torch.tensor(train_images_numpy)  # Convert training images NumPy array to tensor\n",
    "train_labels_tensor = torch.tensor(train_labels_numpy)  # Convert training labels NumPy array to tensor\n",
    "val_images_tensor = torch.tensor(val_images_numpy)      # Convert validation images NumPy array to tensor\n",
    "val_labels_tensor = torch.tensor(val_labels_numpy)      # Convert validation labels NumPy array to tensor"
   ],
   "id": "7c03284d5289e0e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:36.960109Z",
     "start_time": "2024-04-13T12:49:36.955688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)  # Create TensorDataset for training data\n",
    "val_dataset = TensorDataset(val_images_tensor, val_labels_tensor)        # Create TensorDataset for validation data\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)      # Create TensorDataset for testing data\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # Create DataLoader for training data\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)                      # Create DataLoader for validation data\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)                    # Create DataLoader for testing data\n"
   ],
   "id": "498f6d3deb0623ba",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T12:49:47.375147Z",
     "start_time": "2024-04-13T12:49:36.960833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the training, validation, and testing data loaders to files\n",
    "torch.save(train_loader, \"../data/train_loader.pt\")\n",
    "torch.save(val_loader, \"../data/val_loader.pt\")\n",
    "torch.save(test_loader, \"../data/test_loader.pt\")"
   ],
   "id": "6826ad4b23d4de07",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
